在中心节点进行: 
    初始化模型参数 w_0, 并将原始的模型参数 w_0 播给所有的参与方。 
    for 每一全局模型更新轮次 t = 1,2 ...:
        协调方确定 C_t.即确定随机选取的 max(K_p,1)个参与方的集合
        for 每一参与方 k in C_t 并行地:
            # 即在此调用参与方工作函数
            本地更新模型参数: w^k_(t+1) <- 参与方更新（(k, wb_t）
            将更新后的模型参数 w^k_(t+1) 发送给协调方
        协调方将收到的模型参数进行聚合，即对收到的模型参数使用加权平均
        if 协调方检查模型参数已经收敛:
            协调方给各参与方发信号，使其全部停止模型训练。 
        协调方将聚合后的模型参数wb_(t+1)广播给所有参与方。 
        

在参与方进行:#参与方工作函数
    从服务器获得最新的模型参数w^k = wb_t
    for 从 1 到迭代次数 S 的每一次本地迭代 i :
        批量(batches) <- 随机地将数据集 D.划分为批量 M 的大小
        从上一次迭代获得本地模型参数,即设w^k_(1,i) = w^k_(B,i-1)
        for 从 1 到批量数量 B 的批量序号 b:
            计算批量梯度g^b_k
            本地更新模型参数w^k_(b+1,i) <- w^k_(b,i) - alpha * g^b_k
    获得本地模型参数更新w^k_(t+1) = w^k_(B,S)并将其发送给协调方
